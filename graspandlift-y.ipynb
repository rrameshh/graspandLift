{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4477,"databundleVersionId":44220,"sourceType":"competition"}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-29T19:32:37.439639Z","iopub.execute_input":"2024-01-29T19:32:37.440123Z","iopub.status.idle":"2024-01-29T19:32:37.454471Z","shell.execute_reply.started":"2024-01-29T19:32:37.440089Z","shell.execute_reply":"2024-01-29T19:32:37.453256Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"/kaggle/input/grasp-and-lift-eeg-detection/train.zip\n/kaggle/input/grasp-and-lift-eeg-detection/sample_submission.csv.zip\n/kaggle/input/grasp-and-lift-eeg-detection/test.zip\n","output_type":"stream"}]},{"cell_type":"code","source":"import zipfile\nwith zipfile.ZipFile(\"../input/grasp-and-lift-eeg-detection/test.zip\",\"r\") as z:\n    z.extractall(\".\")\nwith zipfile.ZipFile(\"../input/grasp-and-lift-eeg-detection/train.zip\",\"r\") as z:\n    z.extractall(\".\")","metadata":{"execution":{"iopub.status.busy":"2024-01-29T19:32:39.026767Z","iopub.execute_input":"2024-01-29T19:32:39.027207Z","iopub.status.idle":"2024-01-29T19:33:13.611992Z","shell.execute_reply.started":"2024-01-29T19:32:39.027171Z","shell.execute_reply":"2024-01-29T19:33:13.610840Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom zipfile import ZipFile\nimport matplotlib.pyplot as plt\nimport os\nimport pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn as nn\nimport torch.optim as optim\nimport random\nimport torch.nn.functional as F\nimport argparse\nfrom sklearn import metrics\nfrom tqdm.notebook import tqdm\nimport gc\nimport shutil \n\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport pywt\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom glob import glob\nimport scipy\nfrom scipy.signal import butter, lfilter, convolve, boxcar\nfrom scipy.signal import freqz\nfrom scipy.fftpack import fft, ifft\nimport os\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import StandardScaler,Normalizer,MinMaxScaler\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.layers import Embedding\nfrom keras.layers import LSTM, BatchNormalization, Conv2D, Flatten, MaxPooling2D, Dropout, Conv1D, LeakyReLU, MaxPool1D\nfrom keras.optimizers import Adam\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score,roc_curve,auc\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2024-01-29T19:37:49.158870Z","iopub.execute_input":"2024-01-29T19:37:49.159979Z","iopub.status.idle":"2024-01-29T19:37:49.171860Z","shell.execute_reply.started":"2024-01-29T19:37:49.159939Z","shell.execute_reply":"2024-01-29T19:37:49.170602Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"%%time\nFILE_PATH = '../input/grasp-and-lift-eeg-detection'\nlist_dir = os.listdir(FILE_PATH)\n\nfor zipfile in list_dir:\n    with ZipFile(os.path.join(FILE_PATH, zipfile), 'r') as z:\n        z.extractall()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T19:37:51.307859Z","iopub.execute_input":"2024-01-29T19:37:51.308640Z","iopub.status.idle":"2024-01-29T19:38:18.435721Z","shell.execute_reply.started":"2024-01-29T19:37:51.308603Z","shell.execute_reply":"2024-01-29T19:38:18.434516Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"CPU times: user 20.4 s, sys: 4.62 s, total: 25.1 s\nWall time: 27.1 s\n","output_type":"stream"}]},{"cell_type":"code","source":"#from something\ndef wavelet_denoising(x, wavelet='db2', level=1):\n    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n    sigma = (1/0.6745) * madev(coeff[-level])\n\n    uthresh = sigma * np.sqrt(2*np.log(len(x)))\n    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n\n    return pywt.waverec(coeff, wavelet, mode='per')\ndef madev(d, axis=None):\n    \"\"\" Mean absolute deviation of a signal \"\"\"\n    return np.mean(np.absolute(d - np.mean(d, axis)), axis)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T19:38:22.975214Z","iopub.execute_input":"2024-01-29T19:38:22.976338Z","iopub.status.idle":"2024-01-29T19:38:22.984116Z","shell.execute_reply.started":"2024-01-29T19:38:22.976290Z","shell.execute_reply":"2024-01-29T19:38:22.982947Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"sample_data = pd.read_csv('/kaggle/working/test/subj4_series9_data.csv')\nsample_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T19:38:26.558074Z","iopub.execute_input":"2024-01-29T19:38:26.558537Z","iopub.status.idle":"2024-01-29T19:38:27.091977Z","shell.execute_reply.started":"2024-01-29T19:38:26.558502Z","shell.execute_reply":"2024-01-29T19:38:27.090793Z"},"trusted":true},"execution_count":79,"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"                id  Fp1  Fp2   F7   F3  Fz   F4   F8  FC5  FC1  ...   P7   P3  \\\n0  subj4_series9_0   -1  136  878 -519 -21   62 -259  -58   -6  ...  400  265   \n1  subj4_series9_1  -56   99  838 -532 -10  180 -253  -61   -1  ...  393  255   \n2  subj4_series9_2 -104   50  800 -474 -14  148 -239  -11   -2  ...  366  236   \n3  subj4_series9_3  -70   48  869 -456   6  118 -228   29   -7  ...  361  215   \n4  subj4_series9_4  -19   31  876 -413  25  119 -200   46   -2  ...  373  222   \n\n    Pz  P4   P8  PO9   O1  Oz   O2  PO10  \n0  151  77  163   65  140  19  -96  -102  \n1  164  88  148   30  140  21 -111  -105  \n2  148  82  141   35  113  20  -98   -77  \n3  146  81  143    6  106  20 -110   -74  \n4  135  99  164   43  120  48  -43   -39  \n\n[5 rows x 33 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Fp1</th>\n      <th>Fp2</th>\n      <th>F7</th>\n      <th>F3</th>\n      <th>Fz</th>\n      <th>F4</th>\n      <th>F8</th>\n      <th>FC5</th>\n      <th>FC1</th>\n      <th>...</th>\n      <th>P7</th>\n      <th>P3</th>\n      <th>Pz</th>\n      <th>P4</th>\n      <th>P8</th>\n      <th>PO9</th>\n      <th>O1</th>\n      <th>Oz</th>\n      <th>O2</th>\n      <th>PO10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>subj4_series9_0</td>\n      <td>-1</td>\n      <td>136</td>\n      <td>878</td>\n      <td>-519</td>\n      <td>-21</td>\n      <td>62</td>\n      <td>-259</td>\n      <td>-58</td>\n      <td>-6</td>\n      <td>...</td>\n      <td>400</td>\n      <td>265</td>\n      <td>151</td>\n      <td>77</td>\n      <td>163</td>\n      <td>65</td>\n      <td>140</td>\n      <td>19</td>\n      <td>-96</td>\n      <td>-102</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>subj4_series9_1</td>\n      <td>-56</td>\n      <td>99</td>\n      <td>838</td>\n      <td>-532</td>\n      <td>-10</td>\n      <td>180</td>\n      <td>-253</td>\n      <td>-61</td>\n      <td>-1</td>\n      <td>...</td>\n      <td>393</td>\n      <td>255</td>\n      <td>164</td>\n      <td>88</td>\n      <td>148</td>\n      <td>30</td>\n      <td>140</td>\n      <td>21</td>\n      <td>-111</td>\n      <td>-105</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>subj4_series9_2</td>\n      <td>-104</td>\n      <td>50</td>\n      <td>800</td>\n      <td>-474</td>\n      <td>-14</td>\n      <td>148</td>\n      <td>-239</td>\n      <td>-11</td>\n      <td>-2</td>\n      <td>...</td>\n      <td>366</td>\n      <td>236</td>\n      <td>148</td>\n      <td>82</td>\n      <td>141</td>\n      <td>35</td>\n      <td>113</td>\n      <td>20</td>\n      <td>-98</td>\n      <td>-77</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>subj4_series9_3</td>\n      <td>-70</td>\n      <td>48</td>\n      <td>869</td>\n      <td>-456</td>\n      <td>6</td>\n      <td>118</td>\n      <td>-228</td>\n      <td>29</td>\n      <td>-7</td>\n      <td>...</td>\n      <td>361</td>\n      <td>215</td>\n      <td>146</td>\n      <td>81</td>\n      <td>143</td>\n      <td>6</td>\n      <td>106</td>\n      <td>20</td>\n      <td>-110</td>\n      <td>-74</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>subj4_series9_4</td>\n      <td>-19</td>\n      <td>31</td>\n      <td>876</td>\n      <td>-413</td>\n      <td>25</td>\n      <td>119</td>\n      <td>-200</td>\n      <td>46</td>\n      <td>-2</td>\n      <td>...</td>\n      <td>373</td>\n      <td>222</td>\n      <td>135</td>\n      <td>99</td>\n      <td>164</td>\n      <td>43</td>\n      <td>120</td>\n      <td>48</td>\n      <td>-43</td>\n      <td>-39</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 33 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler,Normalizer,MinMaxScaler\n\nscaler= StandardScaler()\ndef trainprep(filename):\n    data = pd.read_csv(filename)\n    events_fname = fname.replace('_data','_events')\n    labels= pd.read_csv(events_fname)\n    clean=data.drop(['id' ], axis=1)#remove id\n    labels=labels.drop(['id' ], axis=1)#remove id\n    return  clean,labels\n\ndef testprep(filename):\n    data = pd.read_csv(filename)\n    return data\n\ndef train_preprocess(X):\n    X_prep=scaler.fit_transform(X)\n    return X_prep\ndef test_preprocess(X):\n    X_prep=scaler.transform(X)\n    return X_prep","metadata":{"execution":{"iopub.status.busy":"2024-01-29T19:38:37.181197Z","iopub.execute_input":"2024-01-29T19:38:37.182184Z","iopub.status.idle":"2024-01-29T19:38:37.190386Z","shell.execute_reply.started":"2024-01-29T19:38:37.182138Z","shell.execute_reply":"2024-01-29T19:38:37.189292Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"\nsubjects = range(1,6)\nfrom glob import glob\nimport pandas as pd\nids_tot = []\npred_tot = []\nX_train_butter = []\nfrom sklearn.model_selection import train_test_split\nimport numpy as  np\n\ny_raw= []\nraw = []\ny_rawt= []\nrawt = []\nfor subject in subjects:  \n    filenames =  sorted(glob('train/subj%d_series*_data.csv' % (subject)))\n    for filename in filenames:\n      data,labels=trainprep(fname)\n      raw.append(data)\n      y_raw.append(labels)\n    for filename in filenames:\n      with open(fname) as myfile:\n        head = [next(myfile) for x in range(10)]\n        \nX = pd.concat(raw)\ny = pd.concat(y_raw)\nX_train =np.asarray(X.astype(float))\ny_train = np.asarray(y.astype(float))\n\n#fs = 500.0\n#owcut = 7.0\n#highcut = 30.0\n\n\nx_train_butter=wavelet_denoising(X_train)\nx_train=train_preprocess(x_train_butter)\nsplitrate=-x_train.shape[0]//5*2\nxval=x_train[splitrate:splitrate//2]\nyval=y_train[splitrate:splitrate//2]\nxtest=x_train[splitrate//2:]\nytest=y_train[splitrate//2:]\nxtrain=x_train[:splitrate]\nytrain=y_train[:splitrate]","metadata":{"execution":{"iopub.status.busy":"2024-01-29T19:38:52.758819Z","iopub.execute_input":"2024-01-29T19:38:52.759860Z","iopub.status.idle":"2024-01-29T19:39:34.690203Z","shell.execute_reply.started":"2024-01-29T19:38:52.759820Z","shell.execute_reply":"2024-01-29T19:39:34.689101Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nload = 1\ntime_steps = 1000\nsubsample = 50\nmodel = Sequential()\nmodel.add(Conv2D(filters = 64, kernel_size = (7,7), padding = \"same\", activation = \"relu\", input_shape = (time_steps//subsample, 32, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 64, kernel_size = (5,5), padding = \"same\", activation = \"relu\", input_shape = (time_steps//subsample, 32, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), padding = \"same\", activation = \"relu\", input_shape = (time_steps//subsample, 32, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\nmodel.add(Dense(32, activation = \"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dense(6, activation = \"sigmoid\"))\n\nadam = Adam(lr = 0.0001)\n\nmodel.compile(optimizer = adam, loss = \"categorical_crossentropy\", metrics = ['accuracy','mse'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T19:39:42.723380Z","iopub.execute_input":"2024-01-29T19:39:42.723770Z","iopub.status.idle":"2024-01-29T19:39:42.910641Z","shell.execute_reply.started":"2024-01-29T19:39:42.723740Z","shell.execute_reply":"2024-01-29T19:39:42.909497Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"Model: \"sequential_16\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_36 (Conv2D)          (None, 20, 32, 64)        3200      \n                                                                 \n batch_normalization_53 (Ba  (None, 20, 32, 64)        256       \n tchNormalization)                                               \n                                                                 \n conv2d_37 (Conv2D)          (None, 20, 32, 64)        102464    \n                                                                 \n batch_normalization_54 (Ba  (None, 20, 32, 64)        256       \n tchNormalization)                                               \n                                                                 \n conv2d_38 (Conv2D)          (None, 20, 32, 64)        36928     \n                                                                 \n batch_normalization_55 (Ba  (None, 20, 32, 64)        256       \n tchNormalization)                                               \n                                                                 \n flatten_13 (Flatten)        (None, 40960)             0         \n                                                                 \n dense_26 (Dense)            (None, 32)                1310752   \n                                                                 \n batch_normalization_56 (Ba  (None, 32)                128       \n tchNormalization)                                               \n                                                                 \n dense_27 (Dense)            (None, 6)                 198       \n                                                                 \n=================================================================\nTotal params: 1454438 (5.55 MB)\nTrainable params: 1453990 (5.55 MB)\nNon-trainable params: 448 (1.75 KB)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"def valgenerator():\n    while 1:\n        batch_size=32\n        x_time_data = np.zeros((batch_size, time_steps//subsample, 32))\n        yy = []\n        for i in range(batch_size):\n            random_index = np.random.randint(0, len(xval)-time_steps)\n            x_time_data[i] = xval[random_index:random_index+time_steps:subsample]\n            yy.append(yval[random_index + time_steps])\n        yy = np.asarray(yy)\n        yield x_time_data.reshape((x_time_data.shape[0],x_time_data.shape[1], x_time_data.shape[2],1)), yy\n    ","metadata":{"execution":{"iopub.status.busy":"2024-01-29T19:39:46.054528Z","iopub.execute_input":"2024-01-29T19:39:46.055616Z","iopub.status.idle":"2024-01-29T19:39:46.063076Z","shell.execute_reply.started":"2024-01-29T19:39:46.055577Z","shell.execute_reply":"2024-01-29T19:39:46.061794Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"import time\nstart=time.time()\ndef generator(batch_size):\n    while 1:\n        x_time_data = np.zeros((batch_size, time_steps//subsample, 32))\n        yy = []\n        for i in range(batch_size):\n            random_index = np.random.randint(0, len(xtrain)-time_steps)\n            x_time_data[i] = xtrain[random_index:random_index+time_steps:subsample]\n            yy.append(ytrain[random_index + time_steps])\n        yy = np.asarray(yy)\n        yield x_time_data.reshape((x_time_data.shape[0],x_time_data.shape[1],  x_time_data.shape[2],1)), yy\n        \n#history =model.fit_generator(generator(32), steps_per_epoch = 600, epochs = 50,validation_data=valgenerator(),\n                              #validation_steps=200)\nhistory =model.fit(generator(32), steps_per_epoch = 600, epochs = 50,validation_data=valgenerator(),\n                              validation_steps=200)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T19:39:48.142134Z","iopub.execute_input":"2024-01-29T19:39:48.142730Z","iopub.status.idle":"2024-01-29T19:44:02.740300Z","shell.execute_reply.started":"2024-01-29T19:39:48.142656Z","shell.execute_reply":"2024-01-29T19:44:02.739105Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"Epoch 1/50\n600/600 [==============================] - 9s 8ms/step - loss: 0.3914 - accuracy: 0.2535 - mse: 0.2237 - val_loss: 0.3743 - val_accuracy: 0.4133 - val_mse: 0.2504\nEpoch 2/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.3708 - accuracy: 0.5265 - mse: 0.2076 - val_loss: 0.3301 - val_accuracy: 0.7716 - val_mse: 0.1553\nEpoch 3/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.3362 - accuracy: 0.7966 - mse: 0.1656 - val_loss: 0.3158 - val_accuracy: 0.8223 - val_mse: 0.1472\nEpoch 4/50\n600/600 [==============================] - 5s 9ms/step - loss: 0.3255 - accuracy: 0.8317 - mse: 0.1472 - val_loss: 0.3557 - val_accuracy: 0.8477 - val_mse: 0.1071\nEpoch 5/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.3199 - accuracy: 0.8434 - mse: 0.1394 - val_loss: 0.2846 - val_accuracy: 0.8547 - val_mse: 0.1109\nEpoch 6/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.3084 - accuracy: 0.8440 - mse: 0.1332 - val_loss: 0.3036 - val_accuracy: 0.8497 - val_mse: 0.1115\nEpoch 7/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2981 - accuracy: 0.8487 - mse: 0.1306 - val_loss: 0.2684 - val_accuracy: 0.8583 - val_mse: 0.1108\nEpoch 8/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.3009 - accuracy: 0.8514 - mse: 0.1297 - val_loss: 0.2874 - val_accuracy: 0.8477 - val_mse: 0.1181\nEpoch 9/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2943 - accuracy: 0.8496 - mse: 0.1267 - val_loss: 0.2553 - val_accuracy: 0.8547 - val_mse: 0.1132\nEpoch 10/50\n600/600 [==============================] - 5s 9ms/step - loss: 0.2824 - accuracy: 0.8566 - mse: 0.1252 - val_loss: 0.2809 - val_accuracy: 0.8500 - val_mse: 0.1285\nEpoch 11/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2871 - accuracy: 0.8527 - mse: 0.1262 - val_loss: 0.2604 - val_accuracy: 0.8527 - val_mse: 0.1223\nEpoch 12/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2872 - accuracy: 0.8548 - mse: 0.1249 - val_loss: 0.2734 - val_accuracy: 0.8512 - val_mse: 0.1273\nEpoch 13/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2878 - accuracy: 0.8496 - mse: 0.1259 - val_loss: 0.2659 - val_accuracy: 0.8591 - val_mse: 0.1212\nEpoch 14/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2862 - accuracy: 0.8497 - mse: 0.1256 - val_loss: 0.2514 - val_accuracy: 0.8464 - val_mse: 0.1313\nEpoch 15/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2829 - accuracy: 0.8489 - mse: 0.1261 - val_loss: 0.2636 - val_accuracy: 0.8427 - val_mse: 0.1391\nEpoch 16/50\n600/600 [==============================] - 6s 9ms/step - loss: 0.2803 - accuracy: 0.8525 - mse: 0.1270 - val_loss: 0.2466 - val_accuracy: 0.8556 - val_mse: 0.1295\nEpoch 17/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2792 - accuracy: 0.8505 - mse: 0.1263 - val_loss: 0.2357 - val_accuracy: 0.8575 - val_mse: 0.1169\nEpoch 18/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2727 - accuracy: 0.8526 - mse: 0.1256 - val_loss: 0.2451 - val_accuracy: 0.8506 - val_mse: 0.1357\nEpoch 19/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2775 - accuracy: 0.8497 - mse: 0.1269 - val_loss: 0.2462 - val_accuracy: 0.8569 - val_mse: 0.1180\nEpoch 20/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2766 - accuracy: 0.8521 - mse: 0.1258 - val_loss: 0.2506 - val_accuracy: 0.8509 - val_mse: 0.1233\nEpoch 21/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2780 - accuracy: 0.8521 - mse: 0.1240 - val_loss: 0.2861 - val_accuracy: 0.8442 - val_mse: 0.1276\nEpoch 22/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2739 - accuracy: 0.8509 - mse: 0.1233 - val_loss: 0.2511 - val_accuracy: 0.8533 - val_mse: 0.1224\nEpoch 23/50\n600/600 [==============================] - 5s 9ms/step - loss: 0.2771 - accuracy: 0.8531 - mse: 0.1233 - val_loss: 0.2415 - val_accuracy: 0.8556 - val_mse: 0.1272\nEpoch 24/50\n600/600 [==============================] - 5s 9ms/step - loss: 0.2758 - accuracy: 0.8503 - mse: 0.1260 - val_loss: 0.2414 - val_accuracy: 0.8527 - val_mse: 0.1286\nEpoch 25/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2698 - accuracy: 0.8504 - mse: 0.1252 - val_loss: 0.2472 - val_accuracy: 0.8514 - val_mse: 0.1275\nEpoch 26/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2780 - accuracy: 0.8482 - mse: 0.1273 - val_loss: 0.2562 - val_accuracy: 0.8419 - val_mse: 0.1353\nEpoch 27/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2667 - accuracy: 0.8546 - mse: 0.1249 - val_loss: 0.2463 - val_accuracy: 0.8492 - val_mse: 0.1356\nEpoch 28/50\n600/600 [==============================] - 5s 9ms/step - loss: 0.2705 - accuracy: 0.8512 - mse: 0.1270 - val_loss: 0.2672 - val_accuracy: 0.8417 - val_mse: 0.1306\nEpoch 29/50\n600/600 [==============================] - 5s 9ms/step - loss: 0.2740 - accuracy: 0.8502 - mse: 0.1260 - val_loss: 0.2413 - val_accuracy: 0.8470 - val_mse: 0.1329\nEpoch 30/50\n600/600 [==============================] - 5s 9ms/step - loss: 0.2656 - accuracy: 0.8542 - mse: 0.1249 - val_loss: 0.2300 - val_accuracy: 0.8553 - val_mse: 0.1308\nEpoch 31/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2607 - accuracy: 0.8548 - mse: 0.1249 - val_loss: 0.2383 - val_accuracy: 0.8525 - val_mse: 0.1369\nEpoch 32/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2680 - accuracy: 0.8525 - mse: 0.1267 - val_loss: 0.2402 - val_accuracy: 0.8545 - val_mse: 0.1252\nEpoch 33/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2711 - accuracy: 0.8515 - mse: 0.1257 - val_loss: 0.2350 - val_accuracy: 0.8533 - val_mse: 0.1272\nEpoch 34/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2678 - accuracy: 0.8505 - mse: 0.1267 - val_loss: 0.2436 - val_accuracy: 0.8528 - val_mse: 0.1387\nEpoch 35/50\n600/600 [==============================] - 5s 9ms/step - loss: 0.2756 - accuracy: 0.8470 - mse: 0.1289 - val_loss: 0.2430 - val_accuracy: 0.8461 - val_mse: 0.1385\nEpoch 36/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2667 - accuracy: 0.8541 - mse: 0.1256 - val_loss: 0.2456 - val_accuracy: 0.8487 - val_mse: 0.1287\nEpoch 37/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2599 - accuracy: 0.8532 - mse: 0.1285 - val_loss: 0.2448 - val_accuracy: 0.8495 - val_mse: 0.1375\nEpoch 38/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2630 - accuracy: 0.8545 - mse: 0.1239 - val_loss: 0.2358 - val_accuracy: 0.8484 - val_mse: 0.1384\nEpoch 39/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2663 - accuracy: 0.8539 - mse: 0.1250 - val_loss: 0.2172 - val_accuracy: 0.8547 - val_mse: 0.1209\nEpoch 40/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2743 - accuracy: 0.8479 - mse: 0.1295 - val_loss: 0.2616 - val_accuracy: 0.8391 - val_mse: 0.1432\nEpoch 41/50\n600/600 [==============================] - 6s 9ms/step - loss: 0.2640 - accuracy: 0.8579 - mse: 0.1243 - val_loss: 0.2376 - val_accuracy: 0.8511 - val_mse: 0.1333\nEpoch 42/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2630 - accuracy: 0.8538 - mse: 0.1274 - val_loss: 0.2345 - val_accuracy: 0.8483 - val_mse: 0.1336\nEpoch 43/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2685 - accuracy: 0.8519 - mse: 0.1263 - val_loss: 0.2277 - val_accuracy: 0.8527 - val_mse: 0.1227\nEpoch 44/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2677 - accuracy: 0.8528 - mse: 0.1245 - val_loss: 0.2405 - val_accuracy: 0.8541 - val_mse: 0.1313\nEpoch 45/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2705 - accuracy: 0.8515 - mse: 0.1286 - val_loss: 0.2296 - val_accuracy: 0.8566 - val_mse: 0.1294\nEpoch 46/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2692 - accuracy: 0.8485 - mse: 0.1292 - val_loss: 0.2356 - val_accuracy: 0.8511 - val_mse: 0.1361\nEpoch 47/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2651 - accuracy: 0.8520 - mse: 0.1284 - val_loss: 0.2505 - val_accuracy: 0.8484 - val_mse: 0.1389\nEpoch 48/50\n600/600 [==============================] - 5s 9ms/step - loss: 0.2564 - accuracy: 0.8551 - mse: 0.1253 - val_loss: 0.2226 - val_accuracy: 0.8477 - val_mse: 0.1393\nEpoch 49/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2574 - accuracy: 0.8536 - mse: 0.1267 - val_loss: 0.2363 - val_accuracy: 0.8509 - val_mse: 0.1405\nEpoch 50/50\n600/600 [==============================] - 5s 8ms/step - loss: 0.2673 - accuracy: 0.8493 - mse: 0.1303 - val_loss: 0.2294 - val_accuracy: 0.8514 - val_mse: 0.1343\n","output_type":"stream"}]}]}